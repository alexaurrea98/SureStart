## Reflections
#### Day 1: 02.08.2021
I am very excited to be part of Vail spring 2021! What caught my attention about this program in the first place was the fact that it's centered around AI and ML. I recently changed to a computer engineering degree and was wanting to take some machine learning classes, however, my schedule won't allow me to. In this year's VAIL program I hope to learn how to work with AI and deep learning. I also hope to not be intimmidated by this field of study. Lastly, I want to see what I am capable of during the makeathon. I look forward to meeting and working with great people and hope to stay connected for years to come!

#### Day 2: 02.09.2021
Today was great! I got to meet my mentor and he was very nice and helpful. I enjoyed reading about ML. The article made ML a little less intimidating as it explained how mathematical models are used to create these complex problem solvers. It was also helpful to learn the difference between supervised and unsupervised ML methods because we will need to decide which to use for specific problems. Unsupervised learning has to do with building prediction models that find patterns within the data. Supervised learning creates these models with a given patter - data already provided The learning activiy in Jupyter was also very helpeful. I was able to install different pyhton modules I did not have before. Overall, very informative. It is incorrect to say that SciKit may visualize data without other python libraries because it uses those modules to create the data visualization. It works really well with them, but it does not replace them.

#### Day 3: 02.10.2021
Wow, this tensorflow tutorial!! Basically, I understood a tensor to be a compialation of vectors or matrices. That is kind of a basic and generalized definition. I was kind of confused on how tensors and matrices were different. From what I was able to understand, a matrix can be a tensor but a tensor can't necesarily be a matrix. A tensor is more specific where it has to be m^n number of elements, but a matix doesn't necesarily need to. A tensor also has the ability to transform when interacting with other mathematics. This is where it is useful to use tensors for deep learning. A lot of real world problems have many variables and data. Most of the times it is not sufficient to use 3D arrays to store datasets. Tensors are good at storing this data and make it easy to manipulate in order to create ML models. In the tensorflow activity I noticed that there are a lot of layers to ML, but they can be broken down.

#### Day 4: 02.11.2021
I was scrolling through different deep learning applications and I came across a dataset of several texts that are either sarcastic or not sarcastic. The inspiration behind this dataset was to help people distinguish between fake and real news. It also made me think of the robot from the presentation we had the other day of the robot. This robot could detect human movement to know how to react and interact with humans. I think being able to detect sarcasm is a very important human trait. Sarcasm is highly dependent on context, and humans are very good at detecting sarcasm even if it's just through text and not human interaction. Looking at the different options I decided that a recurrent convolutiona NN would do the trick. recurrent networks are good at processing text, which is what we would be doing in this case. The activation that would be best would be sigmoid. This is because the output would either be 1 if the text is sarcastic or 0 if it's not. A sifmoid function is good at tracing these kinds of outputs. Here is the link to the dataset I found: https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection. 

I also had the opportunity to read the article about AI ethics. It posed very interesting thoughts that hadn't occurred to me before. The article focused on ways that one can cheat in ML. It's true that right vs wrong can be succh a grey area when it comes to computers. With everything so readily available via the internet, it's difficult to have a sense of ownership. If we see it on the internet, we get the thought that we should be able to have/view it. I agree that there should be some sort of "code of conduct" but then that raises the question of what that should be and what the exceptions should be for certain things. It's almost as if we need a deep learning algorithim just to ensure what may be right or wrong in ML!

#### Day 9: 02.16.2021
AI game activity:
How do you think AI/ML concepts were utilized in the design of this game? The automated hiring process was an example of a ML tecqunique to automate hiring. The data needed for this to occur began by recording my decisions. Since we needed a larger dataset for our algorithm to work, we borrowed from a bigger company. This is the first fault in ML model because in this specific example, this decision can be highly opinionated. The way I think may not be the way someone else thinks. Something very important to note from this game was that there weren't as many blue applicants as there were orange, so that caused some bias in the data as well. 
An example of a real world problem that could involve ML could be how much funding should be given to a specific school or school district based of "success" academically - suchs as how many students get into prestigious collages. This could be filled with all sorts of bias. Lower income communites will not have many resources and could highly affect these results. Because these schools are in low income communites, they don't have as many resources, so teachers may be scarce, class sizes may be large, tutoring oppotunities may be non-existent, and therefore, they don't oroduce successful college accpentances. This results in the ML model not choosing these schools for funding, when they may be the ones in most need of such funding. There may not be a perfect way to fix all these biases, but one way can be to take into account several factors such as number of students and mean income of families in that school zone.

#### Day 10: 02.17.2021
It can be confusing to diffirentiate Convolutional Neural Networks and Fully Connected Neural Networks because they both have "fully connected" aspects. The difference is that FCNN is where every neuron is connected to all neurons in the next layer. This is not so with CNN. CNNs have layers that breakdown the input into smaller pieces that don't lose important features of the input. These layers are called the convolution and pooling layers. After going through a few of these layers, then that output is flattened and fed into a fully connected layer that determines an output label (a classification). CNNs are useful when making classifications for datasets that contain images or videos because they have many pixels and therefore, a lot of data to get through. A FCNN would take longer to process all of that data. FCNNs would be good to use when it is essential that nothing is lost or "assumed" from the input dataset. 

#### Day 16: 02.23.2021
The Rectifified Linear Unit(ReLU) activation function is very useful in many ways. It is actually non-linear which allows multiple layers of the network to be activated by ReLU. Another advantage is that because its derivatitve is either a 1 or a 0, the math is less computationally heavy compared to sigmoid and tanh functions. By using several of these ReLU functions, a model is able to perfor essentially as well as a sigmoid and/or tanh function. We have been using this function in almost all of our CNN coding tutorials thus far. This makes me thibk that ReLU has a lot of applications and not so many limitations. It is probably a safe activation function to use when in doubt.

#### Day 22: 03.01.2021
Successful NLP models, like with any other research, can be very beneficial to society. The GPT-2 model was created with good intentions to better assist society in diverse ways. However, if this model was widely shared on an unsupervised level, the results may be catastrophic. People with malicious intentions may use these kinds of models for the wrong reasons. Deploying big NLP models such as GPT-2 is prone to an increase of fraud and decrease of trust in society. This could become a problem if people misuese these models to create false information on social media or try to inpersonate real people. Overall, sharing successes in the research world can be good, but we have to be careful who has access to this. It's a difficult line, because we want this information to be accessible to people in order to help improve, but also not if it will be misused.
